{
    "n_heads": 8,
    "n_layers": 6,
    "n_embd": 512,
    "context_length": 1024,
    "vocab_size": 50304,
    "dropout": 0.1
}